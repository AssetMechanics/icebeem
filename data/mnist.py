import os

import numpy as np
import torch
from PIL import Image
from torch.utils.data import Dataset
from torchvision import datasets

from .utils import single_one_hot_encode


class ContrastiveMNIST(Dataset):
    """
    Custom MNIST dataset for Contrastive learning
    All is explained in __getitem__
    Mainly a wrapper around pytorch's MNIST dataset
    """

    training_file = 'training.pt'
    test_file = 'test.pt'
    classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four',
               '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']

    def __init__(self, root, noise_samples=None, train=True, transform=None, target_transform=None,
                 segment_transform=None, download=False, fmnist=False):
        super().__init__()
        self.train = train  # training set or test set
        self.fmnist = fmnist

        self.root = root
        self.transform = transform
        self.target_transform = target_transform
        self.segment_transform = segment_transform

        if download:
            self.download()

        if not self._check_exists():
            raise RuntimeError('Dataset not found.' +
                               ' You can use download=True to download it')

        if self.train:
            data_file = self.training_file
        else:
            data_file = self.test_file
        self.data, self.segments = torch.load(os.path.join(self.processed_folder, data_file))

        if noise_samples is None:
            self.noise_size = 0
            self.noise_data = None
            self.noise_segments = None
            self.n_labels = 10
        else:
            self.noise_data = noise_samples['data']
            self.noise_size = self.noise_data.shape[0]
            self.noise_segments = noise_samples['labels']
            if len(self.noise_segments.shape) == 2:  # labels are one_hot
                self.n_labels = self.noise_segments.shape[1]
                print('remove one-hot')
                self.noise_segments = torch.argmax(self.noise_segments, dim=1)
            else:
                self.n_labels = torch.max(self.noise_segments)

        self._clip_dset(self.n_labels)


        self.real_size = self.data.shape[0]
        self.total_size = self.real_size + self.noise_size

        self.targets = [0] * self.real_size + [1] * self.noise_size

    def _scale_inputs(self, img):
        shape = img.shape
        x1 = img.view(-1).min()
        x2 = img.view(-1).max()
        a = 255. / (x2 - x1)
        b = -x1*a
        f = lambda x: a*x + b
        return f(img)


    def _clip_dset(self, range):
        labels_to_consider = np.arange(range)
        idx = np.any([self.segments.numpy() == i for i in labels_to_consider], axis=0).nonzero()
        self.segments = self.segments[idx]
        self.data = self.data[idx]
        self.segment_transform = lambda label: single_one_hot_encode(label, n_labels=len(labels_to_consider))
        return self

    def __getitem__(self, index):
        """
        This custom MNIST dataset has
        - half MNIST images, indices [0, self.real_size - 1]
        - half images generated by a flow model, indices [self.real_size, self.total_size - 1 ]

        It returns a tuple:
        - image in PIL.Image format
        - label, either 0 or 1 (true or noisy)
        - segment, which is the class of the image (from 0 to 0)
        """
        sample_from_noise = False
        if index >= self.real_size:
            sample_from_noise = True
            index = index - self.real_size

        if not sample_from_noise:
            img, segment = self.data[index], int(self.segments[index])
            target = 0
            assert target == self.targets[index]

            # doing this so that it is consistent with all other datasets
            # to return a PIL Image
            img = Image.fromarray(img.numpy(), mode='L')

        else:
            img, segment = self.noise_data[index].view(1,28,28), int(self.noise_segments[index])
            # img = self._scale_inputs(torch.sigmoid(img))
            # doing this so that it is consistent with all other datasets
            # to return a PIL Image
            # img = Image.fromarray(img.numpy(), mode='L')
            target = 1
            assert target == self.targets[index + self.real_size]

        if self.transform is not None:
            if not sample_from_noise:
                img = self.transform(img)

        if self.target_transform is not None:
            target = self.target_transform(target)

        if self.segment_transform is not None:
            segment = self.segment_transform(segment)

        return img, segment, target

    def __len__(self):
        return self.total_size

    @property
    def raw_folder(self):
        if self.fmnist:
            return os.path.join(self.root, 'FashionMNIST', 'raw')
        else:
            return os.path.join(self.root, 'MNIST', 'raw')

    @property
    def processed_folder(self):
        if self.fmnist:
            return os.path.join(self.root, 'FashionMNIST', 'processed')
        else:
            return os.path.join(self.root, 'MNIST', 'processed')

    @property
    def class_to_idx(self):
        return {_class: i for i, _class in enumerate(self.classes)}

    def _check_exists(self):
        return (os.path.exists(os.path.join(self.processed_folder,
                                            self.training_file)) and
                os.path.exists(os.path.join(self.processed_folder,
                                            self.test_file)))

    def download(self):
        if self.fmnist:
            datasets.FashionMNIST(self.root, train=self.train, download=True)
        else:
            datasets.MNIST(self.root, train=self.train, download=True)

    def extra_repr(self):
        return "Split: {}".format("Train" if self.train is True else "Test")